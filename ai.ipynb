{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jezza/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import asarray\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "\n",
    "import glob\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense, Softmax, Conv2D, Input, MaxPooling2D, Flatten, RandomContrast\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from joblib import dump\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nCREATE THE .NPZ FILE\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "CREATE THE .NPZ FILE\n",
    "\n",
    "'''\n",
    "# folder_path = './data/MixedTrainingNumpy/'\n",
    "\n",
    "# data = {}\n",
    "\n",
    "# for file in os.listdir(folder_path):\n",
    "#     if file.endswith('.npy'):\n",
    "\n",
    "#         file_path = os.path.join(folder_path, file)\n",
    "#         array = np.load(file_path)\n",
    "\n",
    "#         label = file[0]\n",
    "\n",
    "#         data[label] = array\n",
    "\n",
    "# np.savez('./data/Training.npz', **data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "LOADS AND \"FORMALISES\" DATA SO CAN BE PASSED INTO PREPROCESSING\n",
    "\n",
    "'''\n",
    "\n",
    "def loadData(filePath):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for filename in os.listdir(filePath):\n",
    "        if filename.endswith('.npy'):\n",
    "\n",
    "            img = np.load(os.path.join(filePath, filename))\n",
    "\n",
    "            img = resize(img, (128, 128), anti_aliasing=True) / 255 # TODO Try normalise between -1 and 1\n",
    "\n",
    "            images.append(img)\n",
    "            \n",
    "            label = filename[0]\n",
    "            labels.append(label)\n",
    "\n",
    "    imagesNP = np.array(images)\n",
    "    labelsNP = np.array(labels)\n",
    "\n",
    "    # Adjust this if your labels are not numeric\n",
    "    encoder = LabelEncoder()\n",
    "    intLabels = encoder.fit_transform(labelsNP)\n",
    "    intLabels = to_categorical(intLabels)\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    return imagesNP, intLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtractionModel():\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(128,128,3))) # Images are 100 by 100 and RGB\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))#Break the image into separate sub-image\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Softmax Regression\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dense(units=4, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2289, 128, 128, 3)\n",
      "(2289, 4)\n",
      "(573, 128, 128, 3)\n",
      "(573, 4)\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step\n",
      "(2289, 28800)\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\n",
      "(573, 28800)\n",
      "Random Forest Classifier Accuracy: 91.44851657940663%\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    filePath = './data/MixedTrainingNumpy/'\n",
    "    imagesNP, labelsNP = loadData(filePath)\n",
    "    print(\"Done\")\n",
    "\n",
    "    imTrain, imTest, labTrain, labTest = train_test_split(imagesNP, labelsNP, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(imTrain.shape)\n",
    "    print(labTrain.shape)\n",
    "    print(imTest.shape)\n",
    "    print(labTest.shape)\n",
    "\n",
    "    # kFold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # foldN = 1\n",
    "    # bestLoss = 10\n",
    "\n",
    "    # for train, test in kFold.split(imTrain, labTrain):\n",
    "    #     model = featureExtractionModel()\n",
    "\n",
    "    #     #optimiser = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    #     model.compile(loss='categorical_crossentropy', metrics=['AUC', 'accuracy'])\n",
    "\n",
    "    #     print(f'Training for fold {foldN}...')\n",
    "    #     model.fit(imTrain[train], labTrain[train], epochs=15, batch_size=4, validation_data=(imTrain[test], labTrain[test]))\n",
    "\n",
    "    #     foldN += 1\n",
    "    #     score = model.evaluate(imTrain[test], labTrain[test], verbose=0)\n",
    "    #     print(f'Score for fold {foldN}: {model.metrics_names[0]} of {score[0]}; {model.metrics_names[1]} of {score[1]*100}%')\n",
    "\n",
    "    #     if score[0] < bestLoss:\n",
    "    #         bestLoss = score[0]\n",
    "    #         bestModel = model\n",
    "\n",
    "    # bestModel.save(\"./CNN.h5\")\n",
    "\n",
    "\n",
    "    # test_score = model.evaluate(imTest, labTest, verbose=0)\n",
    "    # print(f'Test Score: Loss = {test_score[0]}; AUC = {test_score[1]*100}%; Accuracy = {test_score[2]*100}%')\n",
    "\n",
    "    model = load_model(\"./CNN.h5\")\n",
    "\n",
    "    featureModel = keras.Model(inputs=model.inputs, outputs=model.layers[-3].output)\n",
    "\n",
    "    featureTrain = featureModel.predict(imTrain)\n",
    "    print(featureTrain.shape)\n",
    "    featureTest = featureModel.predict(imTest)\n",
    "    print(featureTest.shape)\n",
    "\n",
    "    randForest = RandomForestClassifier(n_estimators=1000, random_state=42, max_depth=20, max_features='sqrt', min_samples_leaf=1, min_samples_split=2, bootstrap=False)\n",
    "    randForest.fit(featureTrain, np.argmax(labTrain, axis=1))\n",
    "\n",
    "    rfPred = randForest.predict(featureTest)\n",
    "\n",
    "    accuracy = accuracy_score(np.argmax(labTest, axis=1), rfPred)\n",
    "    print(f'Random Forest Classifier Accuracy: {accuracy * 100}%')\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
